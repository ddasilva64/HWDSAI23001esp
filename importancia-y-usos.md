# Importancia y usos

#### **Oportunidades laborales en DS e Inteligencia Artificial**

La industria de la Ciencia de Datos (Data Science, en adelante DS) y la Inteligencia Artificial (Artificial Intelligence, en adelante AI) está en constante crecimiento.

**Cada vez hay más oportunidades laborales, porque las empresas se están adaptando para tomar decisiones basadas en datos**, para aumentar la calidad de las iniciativas y transformar o crear productos que sean relevantes para sus consumidores.

La demanda de personal capacitado para encontrar y aprovechar estas oportunidades es cada vez mayor.

**Salarios en DS**

Una referencia general para saber cuál es el salario de una persona que se dedica a la DS es el siguiente rango mensual (promedio), según el puesto:

| ámbito geográfico | júnior | senior |
| :---------------: | :----: | :----: |
|       LATAM       | $1.000 | $4,000 |
|       España      | $1.940 | $6.200 |
|         UE        | $2.160 | $8.500 |
|        EEUU       | $2.050 | $9.300 |

Estos salarios confirman que es una industria en crecimiento y en la que hay muchas oportunidades, como alrededor de 300.000 vacantes en LinkedIn.

**Áreas de aplicación**

Los procedimientos de la DS se pueden aplicar a cualquier sector o área que los genere, que generalmente son todos, lo que le da a la profesión una gran versatilidad. Ejemplos:

* Salud
* Educación
* Entretenimiento
* Finanzas
* Internet de las cosas (Internet of Things, IoT)

**Conclusión**

Sería bueno, entonces, que reflexionáramos sobre cómo la recopilación de datos con la ayuda de la tecnología podría impactar en la toma de decisiones, y que podría beneficiar prácticamente a cualquier industria.

Debemos tener la seguridad de que no importa cuál elijamos, podremos encontrar la oportunidad de contribuir con nuestro trabajo como Científico de Datos.

#### **Glosario de la DS y de la AI**

* **Algoritmo**: Dentro de las Matemáticas y de la programación hay una serie de instrucciones o reglas definidas, con un orden y cantidad de pasos para realizar algunos cálculos, procesar datos y resolver problemas.
* **Algoritmo de aprendizaje automático**: En el Aprendizaje Automático (ML) existen diferentes algoritmos, que sirven para generar modelos entrenados, con los que podemos predecir información.
* **Almacenamiento de datos**: Se refiere a guardar y proteger los datos de la computadora dentro una base de datos para garantizar el acceso a los mismos.
* **API**: API o interfaz de programación de aplicaciones es un conjunto de procesos preescritos dentro de la programación de bibliotecas.
* **Aprendizaje Automático (Machine Learning, ML)**: Es una rama de la AI. Su objetivo es que las computadoras aprendan. En ML, las computadoras analizan grandes cantidades de datos y construyen un modelo capaz de generar predicciones para resolver problemas.
* **Backend**: Se refiere a la capa de desarrollo donde se ejecutan los procesos para acceder a los datos de una aplicación. Esto no es visible para los usuarios de la aplicación y se ejecuta en los servidores.
* **Bases de datos**: Es el conjunto de datos pertenecientes a un mismo contexto que se almacenan para su uso en un sistema software. Para gestionar las bases de datos utilizamos un software conocido como motor de base de datos. Algunos comunes son MySQL y PostgreSQL.
* **Bases de datos OLAP**: Son las siglas en inglés de Online Analytical Processing. Son bases de datos especializadas para generar consultas rápidas de grandes cantidades de datos.
* **Bases de Datos OLTP**: Su acrónimo hace referencia a Procesamiento de Transacciones en Línea. Se enfocan en registrar y actualizar datos (transacciones). Son las bases de datos que generalmente se utilizan en todo tipo de aplicaciones donde se encuentran los datos que necesitan.
* **Biblioteca de programación**: Una biblioteca o librería de programación es un conjunto de funciones que otras personas han escrito utilizando un lenguaje de programación. Es básicamente un código que otras personas han escrito y que podemos usar fácilmente dentro de los programas que escribimos. En Python, por ejemplo, existe la biblioteca Pandas que tiene funciones útiles para manipular y analizar datos. Funciones, que el lenguaje no tiene por defecto.
* **DS**: Es un campo que involucra métodos, procesos y sistemas científicos para obtener información a través del análisis de datos y el Aprendizaje Automático (ML). Es básicamente el proceso de descubrir información valiosa a partir de los datos.
* **Computación en la nube**: Estos son servicios en la nube para almacenar, administrar y procesar datos, servidores, bases de datos, redes y software. Con "la nube" se quiere decir que estos funcionan a través de Internet. Servicios que alquilamos de Amazon Web Service, Google Cloud Platform o Microsoft Azure en lugar de tener físicamente un servidor en nuestra empresa.
* **Computación paralela**: Forma de computación en la que muchas instrucciones se ejecutan simultáneamente, al dividir problemas grandes en problemas más pequeños.
* **Datos**: En DS se refiere a aquellos registros de cifras, números o palabras que se almacenan en documentos informáticos y en bases de datos de sistemas informáticos. Son la materia prima con la que trabajamos.
* **ETL**: ETL (Extraer, Transformar y Cargar). Es un tipo de tubería de datos donde extraemos datos de varias fuentes, los transformamos para poder almacenarlos y cargarlos en bases de datos especializadas para su análisis.
* **Frontend**: Se refiere a la capa de desarrollo donde se crea la parte de la aplicación, a la que los usuarios pueden acceder directamente. Todas las interfaces que vemos de Platzi.com son la capa frontend de la aplicación web, que nos da acceso a todos los cursos.
* **Información de valor**: Es información que se ha obtenido después de analizar datos. Generalmente se utiliza para tomar decisiones empresariales, generar estrategias u otras acciones en la organización, por lo que se dice que tiene valor (insights). Por ejemplo, puede ser información sobre qué clientes dejarán de suscribirse a un servicio debido a determinadas situaciones.
* **AI**: En Informática es la inteligencia expresada por las máquinas, es decir, cuando una máquina imita las funciones cognitivas de la mente humana. Son básicamente algoritmos que hacen que las máquinas aprendan por repetición a emular la inteligencia humana natural. Para ello, reconocen patrones en grandes cantidades de datos.
* **Lenguaje de programación**: Se utiliza para dar instrucciones en forma de algoritmos a las computadoras. En el lenguaje se configuran comandos que escribiremos para decirle a la computadora qué debe hacer.
* **Limpieza de datos**: En DS se refiere a limpieza como lacorrección de datos erróneos o faltantes en una tabla o base de datos, éstos se corrigen o eliminan, para poder analizarlos posteriormente.
* **Modelo de máquina (machine model)**: Es la salida de información que se genera cuando un algoritmo de Aprendizaje Automático se entrena con datos. Después de entrenar los modelos predictivos podemos darles nuevos datos similares a los que fueron entrenados y obtendremos una predicción de salida.
* **Pipeline (conducción) de datos**: Una canalización de datos (pipeline) es un proceso en el que, con diferentes pasos y tecnologías movemos y procesamos datos. En Data Science, se utilizan para mover datos de bases de datos OLTP a bases de datos OLAP.
* **Producción - Sistemas en producción**: Poner el software en “producción” significa que la pieza de software está disponible para que la usen sus usuarios. El software no se desarrolla directamente donde los usuarios lo usan, esto se hace internamente y se prueba de antemano. Cuando se considera que está listo para que los usuarios lo usen, es cuando se pone en producción y es posible usarlo. Cuando hablamos de ML en producción, nos referimos a que el software que utilizan los modelos entrenados funciona dentro de las aplicaciones que utilizan los usuarios.
* **Servidores en la nube**: Es un servidor virtual que se ubica en un servidor físico. Este servidor está alojado por un proveedor de servicios como AWS, Microsoft Azure y Google Cloud Platform. Tiene funcionalidades similares a las de un servidor físico, pero puede ser más rentable ya que se alquila un servicio para utilizarlo y no tenemos que comprarlo y tenerlo físicamente en una empresa.
* **Transformar datos**: Transformar implica dividir datos, limpiar nulos, agregar nuevas columnas con nueva información e incluso reformatearlos.
* **Visualización de Datos**: Es el campo que tiene como objetivo representar datos en forma de gráficos. Presentar información visualmente es más eficiente para comunicar cuando tenemos gran cantidad de ellos. Así, se pueden obtener percepciones (insights) más rápidos y claros para poder emprender acciones de manera más eficiente.

#### **¿Qué es la DS?**

Data Science es un proceso en el que **los datos se utilizan para obtener información valiosa**.

**¿Qué hace un científico de datos?**

Generalmente, la persona que desempeña **el papel de científico de datos está a cargo de tomar datos de varias fuentes y analizarlos**. Esto lo hace con el objetivo de **encontrar información valiosa para el negocio, así como diseñar** **Modelos de ML**, con el objetivo de tomar mejores decisiones dentro de la organización e incorporar los datos al producto.

**Día a día de un científico de datos**

Dentro de la rutina diaria de un **científico de datos**, encontramos:

* **Extraer, limpiar y analizar** datos de varias fuentes
* Diseñar y utilizar **Modelos de ML**
* **Monitorear la precisión de los datos**, para la mejor calidad y confiabilidad
* **Automatizar los procesos de recopilación y transformación de datos** para hacer que todo sea mucho más ágil
* **Crear informes** en dashboards
* **Implementar modelos de ML** en el producto
* **Añadir datos** a los productos

**Diferencia entre cintífico de datos y analista de datos**

Son roles muy similares, **pero tienen ciertas diferencias**, como por ejemplo que el **el científico de datos se enfoca en analizar datos para producir distintos modelos y poder predecir el futuro** con programación avanzada como P.O.O. (Programación Orientada a Objetos).

Mientras que el **analista de datos se enfoca en responder preguntas de negocio, de las demás áreas, por medio del análisis de datos del presente** y con una programación fundamental.

![Analista de datos vs científico de datos](https://i.imgur.com/9ooKGqm.png)

**Conclusión**

En resumen, un científico de datos **usualmente es el encargado de dirigir el equipo de datos en sus proyectos**. Además de utilizar diversas herramientas para analizar el presente y predecir el futuro, en la medida de lo posible, con el fin de encontrar información valiosa para el negocio o proyecto.

![Integración de la ML en el producto](https://i.imgur.com/FwWklLI.png)

**Objetivos de la DS**

* Tomar decisiones
* Crear estrategias de negocio
* Producir software basados en AI

**Proceso de la DS**

1. **Obtener datos** (mediciones directas, encuestas y fuentes de Internet)
2. **Transformar o limpiar datos** (dar formato correcto, eliminar o marcar errores y espacios en blanco o nulos)
3. **Explorar, analizar y visualizar datos** (buscar, organizar y representar gráficamente la información)
4. **Usar modelos de ML** (predecir información)
5. **Escalar modelos de ML** (poner los modelos a disposición de los usuarios)

![Proceso de DS](https://i.imgur.com/lEdhSHk.png)

**El proceso de la DS dependerá en gran medida del proyecto o empresa en la que se trabaje, pero algo general es que se basa en el método científico**. Por lo que se debe tener muy claro cuál es la pregunta y objetivo del caso de negocio. Ya que es un ciclo, es decir que se repetirá constantemente.

**Crear un plan de DS bien estructurado siguiendo el método científico**

**Todos nuestros análisis deben partir de una hipótesis**. Si con nuestro análisis no resolvemos un problema, entonces es irrelevante.

Debemos pensar previamente en la hipótesis o problema que planteamos, la información disponible que necesitamoss, el alcance de nuestro proyecto y las posibles soluciones. Eso nos ayudará a enfocarnos en lo principal y a hacer mejor uso del tiempo y a desarrollar nuestra historia.

![Método científico en DS](https://i.imgur.com/ikqpWTP.png)

No perdamos el tiempo, sigamos el **método científico**:

1. **Observar** la información de nuestro negocio
2. A partir de nuestras observaciones **plantearemos una pregunta** (relevante).
3. A partir de nuestra pregunta, realizaremos una **investigación** a fondo analizando nuestros datos.
4. A partir de la investigación **plantearemos una hipótesis**.
5. Probaremos nuestras hipótesis con **experimentos** diseñados a tal efecto.
6. **Validaremos** los resultados generados por nuestros experimentos.\
   6.1. Si los **resultados son inválidos**, debemos **volver a la investigación**.
7. Si los resultados son correctos, nuestro experimento está listo para crecer, pero no está concluido.\
   7.1. Para no olvidar el trabajo realizado, debemos **documentar** todo el proceso y explicar el progreso de nuestros resultados con storytelling.
8. **Volveremos a empezar** con un nuevo experimento más ambicioso, si fuese necesario.

**Utilizar técnicas de storytelling para presentar los análisis**

**Las personas creemos en historias**. Debemos aplicar storytelling a los resultados de nuestros análisis e informes para aumentar el impacto de nuestro trabajo.

Las especificaciones técnicas de nuestro modelo son el motor del análisis, pero a (casi) nadie le importan. Si queremos cautivar a nuestro equipo con nuestros análisis e informes, debemos contarles una historia, explicando:

1. ¿**Qué** resolvemos?.
2. ¿**Cómo** lo resolvemos?.
3. ¿Cuál es nuestro objetivo?, es decir, ¿**por qué** lo resolvemos?

Debemos deslúmbralos desde el título. Todos deben sentir que nuestro análisis es crucial.

Debemos aplicar técnicas de storytelling para convertir problemas de datos en historias.

![Análisis con Storytelling](https://i.imgur.com/1MwX8Ur.jpg)

**Áreas de conocimientos en DS**

Es una **intersección de varias áreas de conocimiento**, entre las que se encuentran:

* Matemáticas (especialmente Probabilidad y Estadística)
* Informática
* Conocimiento del dominio o sector del negocio

![Áreas conociemiento DS](https://i.imgur.com/OiGRrLY.png)

El nivel de profundidad de cada una de estas áreas se va a determinar de acuerdo al rol que desarrollemos. Sin embargo, algunas habilidades básicas para todos los roles serían: Programación, Estadística Descriptiva, Probabilidad y mantenerse actualizado sobre lo que pasa alrededor de la industria en que nos encontramos (dominio).

**Conclusión**

En conclusión, la **DS** es un campo que se encarga de **utilizar múltiples herramientas para encontrar información valiosa, dentro de los datos**, tanto del presente, como del posible futuro.

#### **¿Qué es la AI? ¿Cuál es su diferencia con la DS?**

La **AI** (A.I. por sus siglas en inglés), trata de enseñar a las máquinas a **emular o imitar la inteligencia natural de los seres humanos**.

Esto lo hacen, las máquinas, **por medio de algoritmos** que modelan cómo aprendemos, cómo tomamos decisiones e identificamos patrones. Algunos ejemplos son: identificar gatitos de perritos o jugar videojuegos.

Una de las grandes hazañas que ha podido lograr la AI fue ganarle a campeones mundiales en Go, Ajedrez y League of Legends, por nombrar algunos. Por supuesto, no fue la misma máquina.

Además, una aclaración importante es que la AI está **limitada**, de cierto modo, porque **no puede tener consciencia de sí misma** y **no puede tomar sus propias decisiones**.

![DS vs AI](https://i.imgur.com/4bIC90T.png)

**Aprendizaje Automático (Machine Learning, ML)**

Es una **rama de la AI**, que tiene como objetivo **hacer que los ordenadores aprendan determinada habilidad**.

Esto se hace por medio de pasarle **muchos datos** a un **algoritmo**, que posteriormente nos va a arrojar un **modelo**, el cual podrá **resolver problemas por medio de predicciones**, o también implementarlo en un software para **solucionar determinadas situaciones**.

![ML](https://i.imgur.com/KhgI5nF.png)

**Datos de entrenamiento**

Se usan para entrenar un algoritmo y obtener un modelo, que pueda hacer predicciones para resolver problemas e implementarse en un software, para un mejor rendimiento en el negocio.

**Datos de entrada**

Se los proporcionamos al modelo, obtenido tras de ser entrenado, que son del mismo contexto que los de entrenamiento, pero con diferentes detalles. Con ellos se van a generar predicciones que serán evaluadas para garantizar la eficacia del modelo.

**Utilidad del ML**

Por ejemplo, si queremos saber cuándo tendremos una perdida masiva de clientes, podemos hacer un modelo que haga esa predicción. Además, podemos saber cuándo y qué producto ofrecerles para no perderlos.

Por otra parte, si queremos saber si un paciente es propenso a padecer una enfermedad específica en el futuro, podemos hacer un modelo que realice una predicción para detectar dicha enfermedad en las primeras etapas o de prevenirla.

**¿Qué hace un ingeniero de Aprendizaje Automático?**

La persona con el rol de **Ingeniero de ML toma los modelos de ML formulados por Data Science, para su posterior seguimiento y evaluación**. También maneja la **implementación directamente con el producto**, ya que este rol es responsable de **mantener esos modelos actualizados**.

**El día a día de un Ingeniero de ML**

Todos los días tendremos que enfrentarnos a las siguientes actividades, si queremos convertirnos en un Ingeniero de Aprendizaje Automático:

* Generar muchas **evaluaciones de métricas** de modelos de ML
* **Implementar el modelo** de ML en producción
* **Colaborar** con el equipo de DS y desarrollo de productos
* **Analizar el rendimiento de los modelos** de aprendizaje automático
* **Mantener el modelo** de Aprendizaje Automático **actualizado**

**Conclusión**

En resumen, un **Ingeniero de aprendizaje automático** monitorea, evalúa y corrige los modelos propuestos por el **Científico de datos** y crea un producto con los desarrolladores, implementando los modelos de \*\*Aprendizaje automático \*\*.

**Proceso de integración de ML al producto**

Hay equipos encargados de implementar modelos de ML en el producto. Por ejemplo: el algoritmo de recomendaciones de Netflix o YouTube, quienes por medio de los datos que el usuario crea, al interactuar con la plataforma, predice cuáles son los videos que más podrían interesarle.

Los pasos para la integración del **ML** al producto son:

1. **Captación** de los datos
2. **Validación** de los datos
3. **Preparación** de los datos
4. **Entrenamiento** del modelo
5. **Evaluación** del modelo
6. **Validación** del modelo
7. **Despliegue** del modelo
8. **Interfaz** de usuario

**Diferencias entre DS e AI**

**DS** es el proceso para **analizar los datos y generar predicciones valiosas**, para la **toma de decisiones y creación de productos**.

La **AI** se refiere a los algoritmos que sirven para predecir eventos en el futuro, imitando la inteligencia humana.

**Relación entre DS y la AI**

En la **DS** se utiliza como una **herramienta la AI para predecir el futuro**, por medio de modelos, que evaluados pueden hacer pronósticos, emulando cierta habilidad del ser humano, al analizar grandes cantidades de datos.

**Conclusión**

Finalmente, podemos decir que la AI se refiere a las máquinas emulando la cognición humana y su principal diferencia es que es una herramienta que es utilizada en el proceso de Data Science para encontrar información valiosa.

|                                                      **DS**                                                      |                                  **AI**                                 |
| :--------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------------: |
| Proceso de análisis de los datos y generación de predicciones para la toma de decisiones y creación de productos | Algoritmos para predecir eventos futuros que emulan la cognición humana |

|                                 **Ambas**                                 |
| :-----------------------------------------------------------------------: |
| En el proceso de Ciencia de utilizamos la AI como una de sus herramientas |

#### **¿Qué es Big Data? ¿Cuál es su diferencia con la DS?**

**Big Data** es una **grandísima cantidad de datos** que tiene una empresa u organización, para trabajar. Estos datos generalmente no se pueden manejar de manera tradicional, debido a su enorme tamaño.

**5 V’s del Big Data**

Para que los datos sean considerados Big Data deben cumplir con las 5 V’s del Big Data. Que son las siguientes:

1. **Volumen**: La organización tiene gran cantidad de datos, desde su funcionamiento, hasta las interacciones de los usuarios.
2. **Velocidad**: Los datos del Big Data deben tener una velocidad "en vivo", para poder procesarlos de manera adecuada, considerando su tamaño.
3. **Variedad**: Los datos que almacene o transaccione la empresa tienen distintos tipos de formatos.
4. **Veracidad**: Los datos que se tengan en **Big Data deben ser confiables**, porque **en ellos se basarán importantes decisiones del negocio**. 5 **Valor**: Estos datos, que se almacenan, deben proporcionar algún tipo de ventaja a la empresa, a la hora de tomar decisiones o de hacer productos para sus consumidores.

**Procesamiento de Big Data**

El almacenamiento, transformación, análisis e implementación de estos datos del negocio, debe hacerse en distintos ordenadores, debido su gran cantidad y también a las diferentes estrategias que deben utilizarse para que funcione el Big Data.

Algunos servicios que se encargan de dividir este gran problema en partes más pequeñas son: Spark, Hadoop y servicios de cómputo en la nube.

**Relación entre DS, AI y Big Data**

En el procedimiento de búsqueda de información valiosa, que es encargado a la DS, se usa **Big Data para aumentar las posibilidades de tener información más profunda y detallada del negocio**.

Además, **se pueden emplear modelos entrenados de ML** de AI para agilizar y encontrar patrones inesperados.

**Conclusión**

De todo lo anterior se desprende que el Big Data es el concepto que se relaciona, cuando una empresa tiene muchísimos datos y la forma de determinarlo es por medio de las 5v’s.

#### **¿Qué NO es DS? ¿Por qué aprenderla?**

DS no es AI, Matemáticas, Excel o métricas.

**AI**

**Solo es una herramienta utilizada por la DS**, pero no es equivalente o igual.

**Matemáticas**

Las Matemáticas son empleadas para crear fórmulas e interpretar los datos de la organización, pero no es la única herramienta usada para encontrar información de valor.

**Excel**

Es solo uno de los diferentes tipos de archivo que se deben conocer y emplear en DS.

**Métricas**

Las métricas son una de las herramientas para generar un contexto de la empresa, pero estas tienen un trabajo y una interpretación que deben ser proporcionadas en la DS, por medio de otras herramientas.

**Razones para no aprender DS**

En DS existen muchas actividades que no son del todo agradables (para muchas personas), pero que son necesarias para lograr un buen resultado.

* **Si no nos gusta aprender constantemente**: En este ambiente de **Data-Driven** en que viven las empresas, constantemente se producen nuevas tecnologías para hacer más fáciles o sencillos los procesos basados en datos, por lo que se debe estar dispuesto a **aprender nuevas tecnologías que nos ayuden a encontrar información valiosa para el negocio**.
* **Si no nos gusta el trabajo sucio**: Dentro del mundo de la DS, **una gran parte del trabajo consiste en borrar, editar y corregir distintos tipos de errores/omisiones dentro de los datos**, para que estos sean lo más precisos y veraces posibles.
* **Si no nos gusta ayudar a las demás áreas del negocio**: El papel de la DS debe ser de **ayudar** a las demás áreas de la organización, proporcionándoles información relevante para mejorar o verificar distintos procesos, y ayudar, así, **a la mejora contínua de la misma**.
* **Si no nos gusta hacer que las cosas pasen**: La DS debe influir en los comportamientos de las demás áreas del negocio, para obtener mejores resultados que afecten positivamente al mismo.

**Razones para aprender DS**

*   **Tomar decisiones basadas en datos**: Data-Driven es la cultura que caracteriza a las organizaciones que basan sus decisiones en los datos.

    En estas compañías podremos encontrar grandes oportunidades para buscar y encontrar información muy interesante acerca del sector de negocio. Deberemos proporcionar posibles acciones a tomar para aprovechar dicha información.
* **Aplicar Matemáticas y algoritmos**: Los algoritmos y las Matemáticas son las herramientas principales para analizar los datos y **poder extraerles toda la información valiosa que tengan**.
* **Trabajar en una empresa Data-Driven**: A este tipo de empresas les encanta tener personas curiosas e interesadas en sacarle todo el valor posible a los datos, **para crear productos y tomar decisiones**.
*   **Crear productos fuertemente basados en AI**: Una de las grandes funciones de la DS es **buscar información de valor para el negocio** y lo hace a través de la A.I.

    Esto se logra mediante el **entrenamiento de modelos para que las I.A. encuentren patrones inesperados dentro de los datos**, que ayuden a mejorar los productos existentes, o crear nuevos que satisfagan las necesidades de los clientes.

Para dedicarse profesionalmente a la DS se requieren algunas habilidades blandas.

**Conclusión**

En resumen, la DS no es una herramienta, sino un conjunto de las mismas, que se combinan en un proceso, para la búsqueda de información valiosa para el negocio.

Es una forma muy poderosa de ayudar a los proyectos, start-ups y compañías a tomar decisiones y crear productos de alto impacto.

#### **Áreas de aplicación de la DS y de la AI**

Dentro de la AI y de la Ciencia de Datos nos encontramos con muchas áreas y ramas en las cuales se puede profundizar, como el Aprendizaje Automático, el DL o la robótica, entre otros.

**Ramas de la AI**

* **Aprendizaje Automático (Machine Learning, ML)**
* **Aprendizaje Profundo (Deep Learning, DL)**
* **Automatización Robotizada de Procesos (Robotic Process Automation, RPA)**
* **Visión Artificial (Computer Vision, CV)**
* **Procesamiento del Lenguaje Natural (Natural Language Processing, NLP)**
* **Robótica**

**Aprendizaje Automático (Machine Learning, ML)**

Serie de algoritmos que hacen que un sistema sea artificialmente inteligente.

**Tipos de algoritmos de Aprendizaje Automático**

* **De aprendizaje supervisado**: En este aprendizaje somos nosotros quienes guiamos el algoritmo a la respuesta correcta.
* **De aprendizaje sin supervisión**: El algoritmo detecta patrones y agrupa la información con estos patrones. Aquí podemos darle características a los algoritmos y ellos agrupan todo a través de patrones relacionados con esa información.

**Aprendizaje Profundo (Deep Learning, DL)**

Para empezar a entender qué es el Aprendizaje Profundo, primero debemos compararlo con el sistema nervioso humano:

* **Nuestro cerebro** está formado por diferentes núcleos de redes neuronales que tienen unas características de percepción y respuesta muy específicas, es decir, cada red se especializa en tareas especiales y es diferente a las demás redes. Por ejemplo, la percepción de un olor y la respuesta de gusto o disgusto por ese olor; la percepción de un sonido y la transición de ese sonido a las sensaciones.
* **En AI**, los modelos computacionales de Aprendizaje Profundo son una imitación de aquellas características arquitectónicas de nuestro sistema nervioso, lo que permite que cada red neuronal construida artificialmente sea entrenada para tareas específicas.

**¿Por qué se llama Aprendizaje Profundo?**

En el cerebro humano, la arquitectura de las redes neuronales funciona de tal manera que **la información recibida del exterior pasa a través de una gran cantidad de capas antes de convertirse en una respuesta**.

El Aprendizaje Profundo es un conjunto de algoritmos no lineales que se pueden aplicar en el modelado de datos y el reconocimiento de patrones. Cuando nos referimos a una forma no lineal, estamos hablando de las capas de redes neuronales artificiales que se apilan en una jerarquía, que van desde características de bajo nivel de abstracción, hasta características de nivel de abstracción más complejas.

La forma en que funciona el Aprendizaje Profundo es mediante el uso de estas cascadas de capas con unidades de procesamiento que permiten la extracción y transformación de variables. Cada red, dentro de su jerarquía, aplica una transformación a su capa de entrada y utiliza esa información de aprendizaje para crear un modelo estadístico de salida que itera tantas veces como sea necesario, hasta que alcanza un nivel aceptable de precisión y respuesta de aprendizaje.

**Automatización Robotizada de Procesos (Robotic Process Automation, RPA)**

La RPA es una forma de tecnología de automatización de procesos comerciales basada en robots de software metafóricos (bots) o en trabajadores digitales/AI. A veces se denomina robótica de software (que no debe confundirse con software de robot).

En las herramientas tradicionales de automatización del flujo de trabajo, un desarrollador de software produce una lista de acciones para automatizar una tarea y una interfaz con el sistema de back-end utilizando API's internas o un lenguaje de secuencias de comandos dedicado. Por el contrario, los sistemas RPA desarrollan la lista de acciones observando al usuario realizar esa tarea en la GUI de la aplicación y luego realizan la automatización repitiendo esas tareas. Esto puede reducir la barrera para el uso de la automatización en productos, que no disponen de una API para este propósito.

Las herramientas RPA tienen fuertes similitudes técnicas con las herramientas de prueba de GUI. También automatizan las interacciones con la interfaz (GUI) y, a menudo, lo hacen repitiendo un conjunto de acciones de demostración realizadas por un usuario. Las herramientas de RPA difieren de dichos sistemas en que permiten que los datos se manejen en y entre múltiples aplicaciones, por ejemplo, recibir correos electrónicos que contienen una factura, extraer los datos y luego escribirlos en un sistema de contabilidad.

**Visión Artificial (Computer Vision, CV)**

La CV es un campo científico interdisciplinario que se ocupa de cómo los ordenadores pueden obtener una comprensión de alto nivel a partir de imágenes o videos digitales. Desde la perspectiva de la ingeniería, busca comprender y automatizar las tareas que puede realizar el sistema visual humano.

Las tareas propias de la CV incluyen métodos para adquirir, procesar, analizar y comprender imágenes digitales, y la extracción de datos de alta dimensión del mundo real para producir información numérica o simbólica, p. e. en forma de decisiones. La comprensión en este contexto significa la transformación de imágenes visuales (la entrada de la retina), en descripciones del mundo que tienen sentido para los procesos de pensamiento y pueden provocar la acción adecuada. Esta comprensión de la imagen puede verse como la separación de la información simbólica de los datos de la imagen utilizando modelos construidos con la ayuda de la Geometría, la Física, la Estadística y la Teoría del Aprendizaje.

La disciplina científica de la CV se ocupa de la teoría detrás de los sistemas artificiales que extraen información de las imágenes. Los datos de imagen pueden tomar muchas formas, como secuencias de video, vistas de varias cámaras, datos multidimensionales de un escáner 3D o dispositivos médicos de escaneo. La disciplina tecnológica de la CV busca aplicar sus teorías y modelos a la construcción de sistemas de visión artificial.

Los subdominios de la CV incluyen la reconstrucción de escenas, la detección de objetos, la detección de eventos, el seguimiento de video, el reconocimiento de objetos, la estimación de poses en 3D, el aprendizaje, la indexación, la estimación de movimiento, el control visual, el modelado de escenas en 3D y la restauración de imágenes.

**Procesamiento del Lenguaje Natural (Natural Language Processing, NLP)**

El NLP es un subcampo interdisciplinario de la Lingüística, la Informática y la AI que se ocupa de las interacciones entre los ordenadores y el lenguaje humano, en particular, cómo programar los ordenadores para procesar y analizar grandes cantidades de datos del lenguaje natural. El objetivo es un ordenador capaz de "comprender" el contenido de los documentos, incluidos los matices contextuales del lenguaje dentro de ellos. Luego, la tecnología puede extraer con precisión la información y los conocimientos contenidos en los documentos, así como categorizar y organizar los propios documentos.

Los desafíos en el NLP con frecuencia implican el reconocimiento del habla, la comprensión del lenguaje natural y la generación del lenguaje natural.

**Robótica**

La Robótica es una rama interdisciplinaria de la Informática y la Ingeniería. Implica el diseño, la construcción, el funcionamiento y el uso de robots. Su objetivo es diseñar máquinas que puedan ayudar a los humanos. Integra campos de Ingeniería Mecánica, Ingeniería Eléctrica, Cibernética, Mecatrónica, Electrónica, Bioingeniería, Ingeniería Informática, Ingeniería de Control, Matemáticas, etc.

Desarrolla máquinas que pueden sustituir a los humanos y replicar sus acciones. Los robots se pueden usar en muchas situaciones, para muchos propósitos, pero hoy en día muchos se usan en entornos peligrosos (incluida la inspección de materiales radiactivos, detección y desactivación de bombas), procesos de fabricación o donde los humanos no pueden sobrevivir (por ejemplo, en el espacio, bajo el agua, a altas temperaturas y limpieza y contención de materiales peligrosos y radiación). Los robots pueden, también, tomar cualquier forma, pero algunos están hechos para parecerse a los humanos en apariencia. Se afirma que esto ayuda en la aceptación de los robots en ciertos comportamientos replicativos que generalmente realizan las personas. Dichos robots intentan replicar caminar, levantar objetos, hablar, cognición o cualquier otra actividad humana. Muchos de los robots actuales están inspirados en la naturaleza, lo que contribuye al campo de la robótica bioinspirada.

Ciertos robots requieren la entrada del usuario para funcionar, mientras que otros funcionan de forma autónoma. El concepto de crear robots que puedan operar de forma autónoma se remonta a la época clásica, pero la investigación sobre la funcionalidad y los usos potenciales de los robots no creció sustancialmente hasta el siglo XX. A lo largo de la historia, varios académicos, inventores, ingenieros y técnicos han asumido con frecuencia que los robots algún día podrán imitar el comportamiento humano y administrar tareas de manera similar a la humana. Hoy en día, la robótica es un campo en rápido crecimiento, a medida que continúan los avances tecnológicos; la investigación, el diseño y la construcción de nuevos robots sirven para varios propósitos prácticos, ya sea a nivel nacional, comercial o militar. Muchos robots están diseñados para realizar trabajos que son peligrosos para las personas, como desactivar bombas, encontrar sobrevivientes en ruinas inestables y explorar minas y naufragios. La robótica también se utiliza en STEM (ciencia, tecnología, ingeniería y matemáticas) como ayuda para la enseñanza.

**Áreas de la DS (ejemplos de aplicación)**

* **Salud**
* **Procesos de producción**
* **Procesos comerciales**
* **Redes sociales**

**Conclusión**

En definitiva, la industria de la DS y AI tiene una gama amplísima de áreas de aplicación.

#### **Roles en la industria: cómo funcionan los equipos de DS y de AI**

Dentro de la industria de la DS existen varios roles diferenciados, pero esto no siempre ha sido de esta forma. En el pasado las empresas usaban el término científico de datos (data scientist), en referencia a la persona que se encargaba de todas las tareas relacionadas con los datos en general.

![Modern Data Scientist](https://i.imgur.com/nYgJGao.png)

Con el tiempo se fueron creando nuevos términos para referirse a las personas que se encargaban de ciertos procesos dentro del flujo o proceso de los datos.

Además, dentro de una organización no se puede iniciar la implementación de modelos de ML, conjuntamente con el producto, sin antes tener una cultura Data-Driven (para poder hacerlo).

De esta forma se origina la pirámide de las necesidades de la DS.

**Pirámide de necesidades de la DS**

La pirámide de necesidades de la DS nos indica las etapas y el orden, que las empresas deben seguir para su desarrollo en la cultura Data-Driven.

![Pyramid of Data Science needsr](https://i.imgur.com/CGz6yFd.jpg)

1. **Recolección o captura de datos**
   * Instrumentación
   * Logging (creación de cuentas de usuario)
   * Sensores
   * Datos externos
   * Contenido generado por el usuario
2. **Movimiento y almacenamiento**
   * Datos confiables
   * Flujo
   * Infraestructura
     * Pipelines (tuberías): Una tubería en DS es “un conjunto de acciones que cambia los datos sin procesar (y confusos) de varias fuentes (encuestas, comentarios, lista de compras, votos, etc.), a un formato comprensible para que podamos almacenarlos y usarlos, para el análisis.”
   * Extracción, Transformación y Carga (Extract, Transform & Load, ETL)
   * Datos estructurados (es decir, que ya están organizados o clasificados por alguna estructura estándar)
   * Datos no estructurados (están sueltos por ahí)
3. **Exploración y transformación**
   * Limpieza.
   * Detección de anomalías
   * Preparación
4. **Agregaciones y etiquetado**
   * Estadísticas
   * Métricas (son como las medidas de una actividad en concreto)
   * Segmentación
   * Agregaciones
   * Características
   * Entrenamiento de datos
5. **Aprendizaje y optimización**
   * Pruebas A/B: Las pruebas A/B (también conocidas como pruebas de cubo, pruebas de ejecución dividida o pruebas divididas) son una metodología de investigación de la experiencia del usuario. Consisten en un experimento aleatorio que suele implicar dos variantes (A y B), aunque el concepto también puede extenderse a múltiples variantes de una misma variable. Incluye la aplicación de pruebas de hipótesis estadísticas o "pruebas de hipótesis de dos muestras", como se usa en el campo de las estadísticas. Son una forma de comparar múltiples versiones de una sola variable, por ejemplo, probando la respuesta de un sujeto a la variante A contra la variante B y determinando cuál de las variantes es más efectiva.

* Experimentación
* Algoritmos simples de ML
* AI
* DL

**Roles en la industria de la DS**

A las etapas anteriores se les añaden los roles que se van a encargar de hacer las tareas correspondientes, para que los datos sigan su curso. Algunos de estos roles suelen tener un enfoque, ya sea con el negocio o con la ingeniería.

![Roles en la DS](https://i.imgur.com/1bSk80k.jpg)

* **Ingeniero de datos (data engineer)**: Es la persona encargada de **construir y mantener todo el ambiente sobre el que habitarán los datos**. Por lo que se encuentra en la base de la pirámide y **está más enfocado en la Ingeniería**.

![Data Engineer profile](https://i.imgur.com/h8345pc.png)

* **Científico de datos (data scientist)**: Este rol se encarga de **ejecutar los métodos necesarios para analizar la etapa actual, como también de hacer predicciones del futuro por medio de modelos de ML**, con el fin de **encontrar información valiosa para crear estrategias y productos** que beneficien al consumidor.

![Data Scientist profile](https://i.imgur.com/0ZBqBTn.png)

*   **Analista de datos (data analyst)**: **Busca constante necesidades de información que tengan las distintas áreas del negocio**, para poder investigarlas y dar una respuesta que sea útil para la **resolución de problemas y mejoramiento de procesos**.

    A diferencia del rol de científico de datos, este solamente analiza el presente.

![Data Analyst perofile](https://i.imgur.com/nXI5kWx.png)

* **Científico de investigación (research scientist)**: Es un rol reciente en la industria, que traduce los diferentes hallazgos del equipo de datos y las necesidades del negocio para el equipo de datos.
* **Ingeniero de ML (ML engineer)**: Evalúa y da seguimiento a los modelos de ML planteados del científico de datos, como también de comunicarse con el equipo de desarrollo, para la correcta y eficiente implementación de los modelos y el producto.

![ML Engineer vs Data Scientist](https://i.imgur.com/clEyAon.png)

*   **Desarrollador (developer)**: Se encuentra dentro de un equipo de Ingeniería dedicado a desarrollar el producto de la empresa.

    Ya sea en el backend o el frontend, debe ser parte de la implementación de los modelos de ML con el producto.

![Data Science strategy](https://i.imgur.com/j6Rtb38.png)

**Conclusión**

Los roles más importantes en la industria de la DS son:

* Data engineer
* Data scientist
* Data snalyst
* Research scientist
* ML engineer

Eso no quita que existan otros aún más especializados, que demanden las empresas con alto desarrollo de la cultura Data-Driven.

#### **Prueba: Importancia y usos de data science e AI**

* Se puede hacer tantas veces como se quiera.
* Consta de 5 preguntas.
* No hay límite de tiempo para presentarlo, sin estrés.
* Al finalizar se sabrá qué conocimientos deberemos reforzar para dominarlos.
